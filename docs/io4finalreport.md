---
title: Final Report
layout: template
filename: io4finalreport
--- 
# Delete later
[Home](index.md)
[Presentations](io2presentation.md)
[Project Specification](io3projectspecification.md)
[Final report](io4finalreport.md)

# Abstract

# Introduction

# Technical Material 

Hardware component for the self-balancing robot.
<p align="center">
  <img src="Photos/droidparts.jpg" width="50%" height="50%">   
</p>
The overview of the hardware for RD-1 such as all control boards, sensors,and motors.
<p align="center">
  <img src="Photos/mainhw.png" width="75%" height="75%">   
</p>
The body of the final droid.
<p align="center">
  <img src="Photos/droid.png" width="50%" height="50%">   
</p>

# Milestones

# Conclusion 

# References
- We use the TensorFlow Object Detection API. The guide provided instructions for how to set up TensorFlowâ€™s Object Detection API on the Raspberry Pi.[here](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-on-the-Raspberry-Pi)
- The mechanical robot Parts for a self-balance droid (ELEGOO Tumbller) and Arduino boards.[here](https://www.elegoo.com/pages/arduino-kits-support-files)
- Two-degree-of-freedom for controlling the camera.[here](https://www.waveshare.com/wiki/Pan-Tilt_HAT)
- Raspberry Pi 4.[here](https://www.raspberrypi.org/products/)